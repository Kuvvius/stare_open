{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638ed50a-89f6-40f1-87b4-8a6f2def1ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 79\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "client = OpenAI()\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "def pil_to_base64(pil_image):\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    pil_image.save(img_byte_arr, format='PNG')\n",
    "    img_encoded_str = base64.b64encode(img_byte_arr.getvalue()).decode('ascii')\n",
    "    return img_encoded_str\n",
    "\n",
    "\n",
    "def gpt_call_single(query, model):\n",
    "    response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=2048,\n",
    "        )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def extract_answer_from_model_response(model_response):\n",
    "    import re\n",
    "    match = re.search(r'\\\\boxed\\{.*?\\b([A-D]|yes|no)\\b.*?\\}', model_response)\n",
    "    \n",
    "    return match.group(1) if match else \"Z\"\n",
    "\n",
    "\n",
    "# convert PIL image to base64\n",
    "def pil_to_base64(pil_image):\n",
    "    import io\n",
    "    import base64\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    pil_image.save(img_byte_arr, format='PNG')\n",
    "    img_encoded_str = base64.b64encode(img_byte_arr.getvalue()).decode('ascii')\n",
    "    return img_encoded_str\n",
    "\n",
    "\n",
    "\n",
    "def test_gpt_on_VisSim_va(dataset_name, output_dir, model, index, max_tokens=2048, debug=False):\n",
    "\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(f\"VisSim/{dataset_name}\")\n",
    "    dataset = dataset['train']\n",
    "    d_index = list(range(len(dataset)))\n",
    "\n",
    "    \n",
    "    output_path = f\"./{model}_{dataset_name}_{index}.json\"\n",
    "    from collections import defaultdict\n",
    "    acc_by_type = defaultdict(float)\n",
    "    acc_by_difficulty = defaultdict(float)\n",
    "    counts_by_difficulty = defaultdict(int)\n",
    "    counts_by_type = defaultdict(int)\n",
    "\n",
    "    # create output dir\n",
    "    answer_dict= {}\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(d_index, total=len(d_index)):\n",
    "        example = dataset[i]\n",
    "        qid = example['qid']\n",
    "        difficulty_level = example['difficulty_level']\n",
    "        variant = \" \".join(qid.split(\"_\")[1:-1])\n",
    "        # 'Observe the transformation pattern of Shape A through steps 0 to 1. <question_image> Apply the same transformation sequence to Shape B and determine the final shape at step 3. <image_for_B> For reference, the black dots in each panel of the figures indicate the origin. Select the correct answer choice that matches the expected transformation result. <answer_choices>'\n",
    "        A_image = example['A_image']\n",
    "        B_image = example['B_image']\n",
    "        question_info = json.loads(example['question_info'])\n",
    "        question = question_info['question']\n",
    "        choice_image = example['choices']\n",
    "        query = []\n",
    "        prefix, question = question.strip().split(\"<question_image>\")\n",
    "        query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prefix\n",
    "                        })\n",
    "        query.append({\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{pil_to_base64(A_image)}\", \n",
    "                            },\n",
    "                        })\n",
    "        prefix, question = question.split(\"<image_for_B>\")\n",
    "        query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prefix\n",
    "                        })\n",
    "        query.append({\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{pil_to_base64(B_image)}\",\n",
    "                            },\n",
    "                        })\n",
    "        prefix, question = question.split(\"<answer_choices>\")   \n",
    "        query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prefix\n",
    "                        })\n",
    "        query.append({\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{pil_to_base64(choice_image)}\", \n",
    "                            },\n",
    "                        })\n",
    "        if len(question) > 0:\n",
    "            query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": question\n",
    "                        })\n",
    "        query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Please first solve the problem step by step, then put your final answer or a single letter (if it is a multiple choice question) in one \\\"\\\\boxed{}\\\"\"\n",
    "                        })\n",
    "        \n",
    "        # print(query)\n",
    "        response = gpt_call_single(query, model=model)\n",
    "\n",
    "        pred = extract_answer_from_model_response(response)\n",
    "\n",
    "        gt_ans = example['answer']\n",
    "\n",
    "        answer_dict[qid] ={\n",
    "            \"pred\": pred,\n",
    "            \"gt_ans\": gt_ans.lower(),\n",
    "            \"response\": response\n",
    "        }\n",
    "        if \"ans\" not in variant:\n",
    "            acc_by_difficulty[difficulty_level]+= pred.lower() == gt_ans.lower()\n",
    "            counts_by_difficulty[difficulty_level] += 1\n",
    "        acc_by_type[variant] += pred.lower() == gt_ans.lower()\n",
    "        counts_by_type[variant] += 1\n",
    "\n",
    "        if len(answer_dict)%10==0:\n",
    "            np.save(output_path, answer_dict)\n",
    "\n",
    "    # print accuracy\n",
    "    print(dataset, index)\n",
    "    print(\"Accuracy by difficulty level:\")\n",
    "    for k, v in acc_by_difficulty.items():\n",
    "        print(f\"{k}: {v/counts_by_difficulty[k]}\")\n",
    "\n",
    "    print(\"Accuracy by variants:\")\n",
    "    for k, v in acc_by_type.items():\n",
    "        print(f\"{k}: {v/counts_by_type[k]}\")\n",
    "    \n",
    "    overall_acc = sum(acc_by_difficulty.values())/sum(counts_by_difficulty.values())\n",
    "    print(f\"Overall accuracy: {overall_acc}\")\n",
    "    np.save(output_path, answer_dict)\n",
    "\n",
    "def test_gpt_on_VisSim_text_inst(dataset_name, output_dir, model, index, max_tokens=2048,debug=False):\n",
    "\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(f\"VisSim/{dataset_name}\")\n",
    "    dataset = dataset['train']\n",
    "    d_index = list(range(len(dataset)))\n",
    "   \n",
    "\n",
    "\n",
    "    from collections import defaultdict\n",
    "    acc_by_type = defaultdict(float)\n",
    "    acc_by_difficulty = defaultdict(float)\n",
    "    counts_by_difficulty = defaultdict(int)\n",
    "    counts_by_type = defaultdict(int)\n",
    "\n",
    "    output_path  = f\"./{model}_{dataset_name}_{index}.json\"\n",
    "    if os.path.exists(output_path+\".npy\"):\n",
    "        answer_dict = np.load(output_path+\".npy\", allow_pickle=True).item()\n",
    "    else:\n",
    "        answer_dict={}\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(d_index, total=len(d_index)):\n",
    "        example = dataset[i]\n",
    "        qid = example['qid']\n",
    "        if qid in answer_dict:\n",
    "            continue\n",
    "        difficulty_level = example['difficulty_level']\n",
    "        variant = \" \".join(qid.split(\"_\")[1:-1])\n",
    "        \n",
    "        images = example['images'][:-1]\n",
    "        # question_info = json.loads(example['question_info'])\n",
    "        question = example['question']\n",
    "        choice_image = example['choices']\n",
    "\n",
    "        # use regex to parse the question and place the images in the right spots\n",
    "        query = []\n",
    "        for i, image in enumerate(images):\n",
    "            if i == 0:\n",
    "                prefix, question = question.strip().split(\"<shapeB_image>\")\n",
    "            else:\n",
    "                prefix, question = question.split(f\"<shapeB_step_{i-1}>\")\n",
    "            query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prefix\n",
    "                        })\n",
    "            query.append({\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{pil_to_base64(image)}\",\n",
    "                            },\n",
    "                        })\n",
    "        \n",
    "        # replace the remaining <shapeB_image> with \"\" using regex\n",
    "        import re\n",
    "        # using wildcards to match the <shapeB_step_{i}> and replace it with \"\"\n",
    "        uery.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": re.sub(r'<shapeB_step_\\d+>', '', question)\n",
    "                        })\n",
    "        query.append({\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{pil_to_base64(choice_image)}\",\n",
    "                            },\n",
    "                        })\n",
    "        \n",
    "        query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Please first solve the problem step by step, then put your final answer or a single letter (if it is a multiple choice question) in one \\\"\\\\boxed{}\\\"\"\n",
    "                        })\n",
    "        response = gpt_call_single(query, model=model)\n",
    "\n",
    "        pred = extract_answer_from_model_response(response)\n",
    "\n",
    "        gt_ans = example['answer']\n",
    "\n",
    "        answer_dict[qid]={\n",
    "            \"pred\": pred,\n",
    "            \"gt_ans\": gt_ans.lower(),\n",
    "            \"response\": response\n",
    "        }\n",
    "        if len(answer_dict)%10==0:\n",
    "            np.save(output_path, answer_dict)\n",
    "        if \"ans\" not in variant:\n",
    "            acc_by_difficulty[difficulty_level]+= pred.lower() == gt_ans.lower()\n",
    "            counts_by_difficulty[difficulty_level] += 1\n",
    "        acc_by_type[variant] += pred.lower() == gt_ans.lower()\n",
    "        counts_by_type[variant] += 1\n",
    "\n",
    "    # print accuracy\n",
    "    np.save(output_path, answer_dict)\n",
    "    print(\"Accuracy by difficulty level:\")\n",
    "    for k, v in acc_by_difficulty.items():\n",
    "        print(f\"{k}: {v/counts_by_difficulty[k]}\")\n",
    "\n",
    "    print(\"Accuracy by variants:\")\n",
    "    for k, v in acc_by_type.items():\n",
    "        print(f\"{k}: {v/counts_by_type[k]}\")\n",
    "    \n",
    "    overall_acc = sum(acc_by_difficulty.values())/sum(counts_by_difficulty.values())\n",
    "    print(f\"Overall accuracy: {overall_acc}\")\n",
    "\n",
    "\n",
    "\n",
    "def test_gpt_on_folding_nets(dataset_name, output_dir, model, index, max_tokens=2048,debug=False):\n",
    "\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(f\"VisSim/{dataset_name}\")\n",
    "    dataset = dataset['train']\n",
    "    d_index = list(range(len(dataset)))\n",
    "\n",
    "\n",
    "    from collections import defaultdict\n",
    "    pred_by_type = defaultdict(list)\n",
    "    pred_by_difficulty = defaultdict(list)\n",
    "\n",
    "    gt_by_type = defaultdict(list)\n",
    "    gt_by_difficulty = defaultdict(list)\n",
    "\n",
    "    \n",
    "    output_path  = f\"./{model}_{dataset_name}_{index}.json\"\n",
    "    if os.path.exists(output_path+\".npy\"):\n",
    "        answer_dict = np.load(output_path+\".npy\", allow_pickle=True).item()\n",
    "    else:\n",
    "        answer_dict={}\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(d_index, total=len(d_index)):\n",
    "        example = dataset[i]\n",
    "        qid = example['qid']\n",
    "        if qid in answer_dict:\n",
    "            continue\n",
    "        variant = example['type']\n",
    "  \n",
    "        images = example['images']\n",
    "        # question_info = json.loads(example['question_info'])\n",
    "        question = example['question']\n",
    "\n",
    "        # use regex to parse the question and place the images in the right spots\n",
    "        query = []\n",
    "        for i, image in enumerate(images):\n",
    "            prefix, question = question.split(f\"<image_{i}>\")\n",
    "            query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prefix\n",
    "                        })\n",
    "            query.append({\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{pil_to_base64(choice_image)}\",\n",
    "                            },\n",
    "                        })\n",
    "        if len(question) > 0:\n",
    "            query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": question + \"Think step-by-step, and then put your final answer in \\\"\\\\boxed{}\\\".\"\n",
    "                        })\n",
    "        else:\n",
    "            query.append({\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Think step-by-step, and then put your final answer in \\\"\\\\boxed{}\\\".\"\n",
    "                        })\n",
    "        \n",
    "        \n",
    "        response = gpt_call_single(query, model=model)\n",
    "\n",
    "        pred = extract_answer_from_model_response(response.lower())\n",
    "\n",
    "        gt_choice = example['answer'].lower()\n",
    "        answer_choices = example['choices']\n",
    "\n",
    "        gt_ans = answer_choices[int(ord(gt_choice) - ord('a'))]\n",
    "\n",
    "        answer_dict[ qid]={\n",
    "            \"pred\": pred,\n",
    "            \"gt_choice\": gt_choice,\n",
    "            \"gt_ans\": gt_ans.lower(),\n",
    "            \"response\": response,\n",
    "            \"question\": [q  if isinstance(q, str) else '<image>' for q in query]\n",
    "        }\n",
    "        if len(answer_dict)%10==0:\n",
    "            np.save(output_path, answer_dict)\n",
    "        correct = pred.lower() == gt_ans.lower() or pred.lower() == gt_choice.lower()\n",
    "        pred_by_type[variant].append(pred.lower())\n",
    "        gt_by_type[variant].append(gt_ans.lower())\n",
    "\n",
    "    np.save(output_path, answer_dict)\n",
    "    print(\"F1 by variants:\")\n",
    "    for k in pred_by_type.keys():\n",
    "        from sklearn.metrics import f1_score\n",
    "        print(f\"{k}: {f1_score(gt_by_type[k], pred_by_type[k], average='weighted')}\")\n",
    "\n",
    "    print(\"Random Chance F1 by variants:\")\n",
    "    for k in pred_by_type.keys():\n",
    "        from sklearn.metrics import f1_score\n",
    "        import random\n",
    "        random_pred = [random.choice([\"yes\", \"no\"]) for _ in range(len(gt_by_type[k]))]\n",
    "        print(f\"{k}: {f1_score(gt_by_type[k],random_pred, average='weighted')}\")\n",
    "\n",
    "\n",
    "model = \"gpt-4o\"\n",
    "import os\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
