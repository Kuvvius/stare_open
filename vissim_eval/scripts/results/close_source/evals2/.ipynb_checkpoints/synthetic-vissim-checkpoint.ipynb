{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae5421-e5b1-43a2-861c-80264187be94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                              | 3/306 [01:02<1:44:36, 20.71s/it]"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import numpy as np\n",
    "# load API key\n",
    "GEMINI_API_KEY = \"AIzaSyCxuedQMQWQkYSu67h3L5PMXDg3cDmeeBQ\"\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def gemini_call_single(query, model):\n",
    "    # import cv2\n",
    "    import requests\n",
    "    import time\n",
    "    import json\n",
    "\n",
    "    # print(query)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            content = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=query,\n",
    "                # config = types.GenerateContentConfig(\n",
    "                #     temperature=temp,\n",
    "                # )\n",
    "            )\n",
    "            \n",
    "\n",
    "        except Exception as e_msg:\n",
    "            content = '[ERROR] ' + str(e_msg)\n",
    " \n",
    "        if isinstance(content, str):\n",
    "            content = '[ERROR] ' + content.lower()\n",
    "            if 'exceeded call rate limit' in content or 'exhausted' in content:\n",
    "                # retry for unacceptable response\n",
    "                print('\\n(retry later in 5 seconds...) ->', content)\n",
    "                if \"thinking\" in model:\n",
    "                    time.sleep(10)\n",
    "                else:\n",
    "                    time.sleep(5)\n",
    "                continue\n",
    "            else:\n",
    "                print('\\n(retry later...) ->', content)\n",
    "        elif content.text is None:\n",
    "            temp += 0.1\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    ########################################\n",
    "    \n",
    "    # print(responseJson[\"choices\"][0][\"message\"][\"content\"])\n",
    "    return content.text\n",
    "\n",
    "\n",
    "def extract_answer_from_model_response(model_response):\n",
    "    import re\n",
    "    match = re.search(r'\\\\boxed\\{.*?\\b([A-D])\\b.*?\\}', model_response)\n",
    "    \n",
    "    return match.group(1) if match else \"Z\"\n",
    "\n",
    "\n",
    "# convert PIL image to base64\n",
    "def pil_to_base64(pil_image):\n",
    "    import io\n",
    "    import base64\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    pil_image.save(img_byte_arr, format='PNG')\n",
    "    img_encoded_str = base64.b64encode(img_byte_arr.getvalue()).decode('ascii')\n",
    "    return img_encoded_str\n",
    "\n",
    "\n",
    "\n",
    "def test_gemini_on_VisSim_va(dataset_name, output_dir, model, index, max_tokens=2048, debug=False):\n",
    "\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(f\"VisSim/{dataset_name}\")\n",
    "    dataset = dataset['train']\n",
    "    d_index = list(range(len(dataset)))\n",
    "\n",
    "    \n",
    "    output_path = f\"./{model}_{dataset_name}_{index}.json\"\n",
    "    from collections import defaultdict\n",
    "    acc_by_type = defaultdict(float)\n",
    "    acc_by_difficulty = defaultdict(float)\n",
    "    counts_by_difficulty = defaultdict(int)\n",
    "    counts_by_type = defaultdict(int)\n",
    "\n",
    "    # create output dir\n",
    "    answer_dict= {}\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(d_index, total=len(d_index)):\n",
    "        example = dataset[i]\n",
    "        qid = example['qid']\n",
    "        difficulty_level = example['difficulty_level']\n",
    "        variant = \" \".join(qid.split(\"_\")[1:-1])\n",
    "        # 'Observe the transformation pattern of Shape A through steps 0 to 1. <question_image> Apply the same transformation sequence to Shape B and determine the final shape at step 3. <image_for_B> For reference, the black dots in each panel of the figures indicate the origin. Select the correct answer choice that matches the expected transformation result. <answer_choices>'\n",
    "        A_image = example['A_image']\n",
    "        B_image = example['B_image']\n",
    "        question_info = json.loads(example['question_info'])\n",
    "        question = question_info['question']\n",
    "        choice_image = example['choices']\n",
    "        query = []\n",
    "        prefix, question = question.strip().split(\"<question_image>\")\n",
    "        query.append(prefix)\n",
    "        query.append(A_image)\n",
    "        prefix, question = question.split(\"<image_for_B>\")\n",
    "        query.append(prefix)\n",
    "        query.append(B_image)\n",
    "        prefix, question = question.split(\"<answer_choices>\")   \n",
    "        query.append(prefix)\n",
    "        query.append(choice_image)\n",
    "        if len(question) > 0:\n",
    "            query.append(question)\n",
    "        query.append(\"Please first solve the problem step by step, then put your final answer or a single letter (if it is a multiple choice question) in one \\\"\\\\boxed{}\\\"\")\n",
    "        # print(query)\n",
    "        response = gemini_call_single(query, model=model)\n",
    "\n",
    "        pred = extract_answer_from_model_response(response)\n",
    "\n",
    "        gt_ans = example['answer']\n",
    "\n",
    "        answer_dict[qid] ={\n",
    "            \"pred\": pred,\n",
    "            \"gt_ans\": gt_ans.lower(),\n",
    "            \"response\": response\n",
    "        }\n",
    "            \n",
    "        if \"ans\" not in variant:\n",
    "            acc_by_difficulty[difficulty_level]+= pred.lower() == gt_ans.lower()\n",
    "            counts_by_difficulty[difficulty_level] += 1\n",
    "        acc_by_type[variant] += pred.lower() == gt_ans.lower()\n",
    "        counts_by_type[variant] += 1\n",
    "        # print(answer_dict)\n",
    "        if len(answer_dict)%10==0:\n",
    "            np.save(output_path, answer_dict)\n",
    "\n",
    "    # print accuracy\n",
    "    print(dataset, index)\n",
    "    print(\"Accuracy by difficulty level:\")\n",
    "    for k, v in acc_by_difficulty.items():\n",
    "        print(f\"{k}: {v/counts_by_difficulty[k]}\")\n",
    "\n",
    "    print(\"Accuracy by variants:\")\n",
    "    for k, v in acc_by_type.items():\n",
    "        print(f\"{k}: {v/counts_by_type[k]}\")\n",
    "    \n",
    "    overall_acc = sum(acc_by_difficulty.values())/sum(counts_by_difficulty.values())\n",
    "    print(f\"Overall accuracy: {overall_acc}\")\n",
    "    np.save(output_path, answer_dict)\n",
    "\n",
    "def test_gemini_on_VisSim_text_inst(dataset_name, output_dir, model='gemini-2.0-flash-exp', max_tokens=2048,debug=False):\n",
    "\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(f\"VisSim/{dataset_name}\")\n",
    "    dataset = dataset['train']\n",
    "    d_index = list(range(len(dataset)))\n",
    "    if debug:\n",
    "        import random\n",
    "        random.seed(42)\n",
    "        random.shuffle(d_index)\n",
    "        d_index = d_index[:300]\n",
    "\n",
    "\n",
    "    from collections import defaultdict\n",
    "    acc_by_type = defaultdict(float)\n",
    "    acc_by_difficulty = defaultdict(float)\n",
    "    counts_by_difficulty = defaultdict(int)\n",
    "    counts_by_type = defaultdict(int)\n",
    "\n",
    "    # create output dir\n",
    "    os.makedirs(os.path.join(output_dir, model, dataset_name), exist_ok=True)\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(d_index, total=len(d_index)):\n",
    "        example = dataset[i]\n",
    "        qid = example['qid']\n",
    "        difficulty_level = example['difficulty_level']\n",
    "        variant = \" \".join(qid.split(\"_\")[1:-1])\n",
    "        output_path = os.path.join(output_dir, model, dataset_name + f\"{qid}.json\")\n",
    "        if os.path.exists(output_path):\n",
    "\n",
    "            output = json.load(open(output_path))\n",
    "            pred = output['pred']\n",
    "            gt_ans = output['gt_ans']\n",
    "        else:\n",
    "            images = example['images'][:-1]\n",
    "            # question_info = json.loads(example['question_info'])\n",
    "            question = example['question']\n",
    "            choice_image = example['choices']\n",
    "\n",
    "            # use regex to parse the question and place the images in the right spots\n",
    "            query = []\n",
    "            for i, image in enumerate(images):\n",
    "                if i == 0:\n",
    "                    prefix, question = question.strip().split(\"<shapeB_image>\")\n",
    "                else:\n",
    "                    prefix, question = question.split(f\"<shapeB_step_{i-1}>\")\n",
    "                query.append(prefix)\n",
    "                query.append(image)\n",
    "            \n",
    "            # replace the remaining <shapeB_image> with \"\" using regex\n",
    "            import re\n",
    "            # using wildcards to match the <shapeB_step_{i}> and replace it with \"\"\n",
    "            query.append(re.sub(r'<shapeB_step_\\d+>', '', question))\n",
    "\n",
    "            query.append(choice_image)\n",
    "            \n",
    "            query.append(\"Please first solve the problem step by step, then put your final answer or a single letter (if it is a multiple choice question) in one \\\"\\\\boxed{}\\\"\")\n",
    "            # print(query)\n",
    "            response = gemini_call_single(query, model=model)\n",
    "\n",
    "            pred = extract_answer_from_model_response(response)\n",
    "\n",
    "            gt_ans = example['answer']\n",
    "\n",
    "            output = {\n",
    "                \"qid\": qid,\n",
    "                \"pred\": pred,\n",
    "                \"gt_ans\": gt_ans.lower(),\n",
    "                \"response\": response\n",
    "            }\n",
    "            with open(output_path, \"w\") as f:\n",
    "                json.dump(output, f)\n",
    "        if \"ans\" not in variant:\n",
    "            acc_by_difficulty[difficulty_level]+= pred.lower() == gt_ans.lower()\n",
    "            counts_by_difficulty[difficulty_level] += 1\n",
    "        acc_by_type[variant] += pred.lower() == gt_ans.lower()\n",
    "        counts_by_type[variant] += 1\n",
    "\n",
    "    # print accuracy\n",
    "    print(\"Accuracy by difficulty level:\")\n",
    "    for k, v in acc_by_difficulty.items():\n",
    "        print(f\"{k}: {v/counts_by_difficulty[k]}\")\n",
    "\n",
    "    print(\"Accuracy by variants:\")\n",
    "    for k, v in acc_by_type.items():\n",
    "        print(f\"{k}: {v/counts_by_type[k]}\")\n",
    "    \n",
    "    overall_acc = sum(acc_by_difficulty.values())/sum(counts_by_difficulty.values())\n",
    "    print(f\"Overall accuracy: {overall_acc}\")\n",
    "\n",
    "\n",
    "\n",
    "def test_gemini_on_folding_nets(dataset_name, output_dir, model='gemini-2.0-flash-exp', max_tokens=2048,debug=False):\n",
    "\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(f\"VisSim/{dataset_name}\")\n",
    "    dataset = dataset['train']\n",
    "    d_index = list(range(len(dataset)))\n",
    "    if debug:\n",
    "        import random\n",
    "        random.seed(42)\n",
    "        random.shuffle(d_index)\n",
    "        d_index = d_index[:200]\n",
    "\n",
    "\n",
    "    from collections import defaultdict\n",
    "    pred_by_type = defaultdict(list)\n",
    "    pred_by_difficulty = defaultdict(list)\n",
    "\n",
    "    gt_by_type = defaultdict(list)\n",
    "    gt_by_difficulty = defaultdict(list)\n",
    "\n",
    "\n",
    "    # create output dir\n",
    "    os.makedirs(os.path.join(output_dir, model, dataset_name), exist_ok=True)\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(d_index, total=len(d_index)):\n",
    "        example = dataset[i]\n",
    "        qid = example['qid']\n",
    "        variant = example['type']\n",
    "        output_path = os.path.join(output_dir, model, dataset_name, f\"{qid}.json\")\n",
    "        if os.path.exists(output_path):\n",
    "\n",
    "            output = json.load(open(output_path))\n",
    "            pred = output['pred']\n",
    "            gt_ans = output['gt_ans']\n",
    "            gt_choice = output['gt_choice']\n",
    "        else:\n",
    "            images = example['images']\n",
    "            # question_info = json.loads(example['question_info'])\n",
    "            question = example['question']\n",
    "\n",
    "\n",
    "            # use regex to parse the question and place the images in the right spots\n",
    "            query = []\n",
    "            for i, image in enumerate(images):\n",
    "                prefix, question = question.split(f\"<image_{i}>\")\n",
    "                query.append(prefix)\n",
    "                query.append(image)\n",
    "            if len(question) > 0:\n",
    "                query.append(question + \"Think step-by-step, and then put your final answer in \\\"\\\\boxed{}\\\".\")\n",
    "            else:\n",
    "                query.append(\"Think step-by-step, and then put your final answer in \\\"\\\\boxed{}\\\".\")\n",
    "            \n",
    "            # check if the query has at least 1 image after parsing\n",
    "\n",
    "            # print(query)\n",
    "            response = gemini_call_single(query, model=model)\n",
    "\n",
    "            pred = extract_answer_from_model_response(response)\n",
    "\n",
    "            gt_choice = example['answer'].lower()\n",
    "            answer_choices = example['choices']\n",
    "\n",
    "            gt_ans = answer_choices[int(ord(gt_choice) - ord('a'))]\n",
    "\n",
    "            output = {\n",
    "                \"qid\": qid,\n",
    "                \"pred\": pred,\n",
    "                \"gt_choice\": gt_choice,\n",
    "                \"gt_ans\": gt_ans.lower(),\n",
    "                \"response\": response,\n",
    "                \"question\": [q  if isinstance(q, str) else '<image>' for q in query]\n",
    "            }\n",
    "            with open(output_path, \"w\") as f:\n",
    "                json.dump(output, f)\n",
    "\n",
    "        correct = pred.lower() == gt_ans.lower() or pred.lower() == gt_choice.lower()\n",
    "        pred_by_type[variant].append(pred.lower())\n",
    "        gt_by_type[variant].append(gt_ans.lower())\n",
    "\n",
    "\n",
    "    print(\"F1 by variants:\")\n",
    "    for k in pred_by_type.keys():\n",
    "        from sklearn.metrics import f1_score\n",
    "        print(f\"{k}: {f1_score(gt_by_type[k], pred_by_type[k], average='weighted')}\")\n",
    "\n",
    "    print(\"Random Chance F1 by variants:\")\n",
    "    for k in pred_by_type.keys():\n",
    "        from sklearn.metrics import f1_score\n",
    "        import random\n",
    "        random_pred = [random.choice([\"yes\", \"no\"]) for _ in range(len(gt_by_type[k]))]\n",
    "        print(f\"{k}: {f1_score(gt_by_type[k],random_pred, average='weighted')}\")\n",
    "\n",
    "\n",
    "def test_gemini_flash_thinking(debug=False):\n",
    "    model = 'gemini-2.0-flash-thinking-exp-01-21'\n",
    "    test_gemini_on_VisSim_va('2d_va_vissim_test', '.', model=model, index=0, debug=debug)\n",
    "\n",
    "test_gemini_flash_thinking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4c29bf-d13e-4a80-97e2-7337b0076732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 306/306 [00:10<00:00, 30.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['qid', 'A_image', 'B_image', 'choices', 'answer', 'transformations', 'difficulty_level', 'question_info', 'answer_info'],\n",
      "    num_rows: 306\n",
      "}) 0\n",
      "Accuracy by difficulty level:\n",
      "easy: 0.696078431372549\n",
      "medium: 0.45098039215686275\n",
      "hard: 0.43137254901960786\n",
      "Accuracy by variants:\n",
      "easy no: 0.696078431372549\n",
      "medium no: 0.45098039215686275\n",
      "hard no: 0.43137254901960786\n",
      "Overall accuracy: 0.5261437908496732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = 'gemini-2.0-flash-thinking-exp-01-21'\n",
    "dataset_name = '2d_va_vissim_test'\n",
    "index= 0\n",
    "import numpy as np\n",
    "answer_dict = np.load(\"gemini-2.0-flash-thinking-exp-01-21_2d_va_vissim_test_0.json.npy\", allow_pickle=True).item() \n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(f\"VisSim/{dataset_name}\")\n",
    "dataset = dataset['train']\n",
    "d_index = list(range(len(dataset)))\n",
    "\n",
    "\n",
    "output_path = f\"./{model}_{dataset_name}_{index}.json\"\n",
    "from collections import defaultdict\n",
    "acc_by_type = defaultdict(float)\n",
    "acc_by_difficulty = defaultdict(float)\n",
    "counts_by_difficulty = defaultdict(int)\n",
    "counts_by_type = defaultdict(int)\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(d_index, total=len(d_index)):\n",
    "    example = dataset[i]\n",
    "    qid = example['qid']\n",
    "    difficulty_level = example['difficulty_level']\n",
    "    gt = example['answer']\n",
    "    pred = answer_dict[qid]['pred']\n",
    "    variant = \" \".join(qid.split(\"_\")[1:-1])\n",
    "    gt_ans = example['answer']\n",
    "    if pred==\"Z\":\n",
    "        print(answer_dict[qid]['response'])\n",
    "    if \"ans\" not in variant:\n",
    "        acc_by_difficulty[difficulty_level]+= pred.lower() == gt_ans.lower()\n",
    "        counts_by_difficulty[difficulty_level] += 1\n",
    "    acc_by_type[variant] += pred.lower() == gt_ans.lower()\n",
    "    counts_by_type[variant] += 1\n",
    "\n",
    "    # print accuracy\n",
    "print(dataset, index)\n",
    "print(\"Accuracy by difficulty level:\")\n",
    "for k, v in acc_by_difficulty.items():\n",
    "    print(f\"{k}: {v/counts_by_difficulty[k]}\")\n",
    "\n",
    "print(\"Accuracy by variants:\")\n",
    "for k, v in acc_by_type.items():\n",
    "    print(f\"{k}: {v/counts_by_type[k]}\")\n",
    "\n",
    "overall_acc = sum(acc_by_difficulty.values())/sum(counts_by_difficulty.values())\n",
    "print(f\"Overall accuracy: {overall_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
